# Known Issues & Solutions | å·²çŸ¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

[ğŸ‡ºğŸ‡¸ English](#english) | [ğŸ‡¨ğŸ‡³ ä¸­æ–‡](#chinese)

<a id="english"></a>
## English

This document lists known issues in the project and their solutions.

### Table of Contents
- [Rendering Issues](#rendering-issues)
- [PettingZoo Version Compatibility](#pettingzoo-version-compatibility)
- [Other Common Issues](#other-common-issues)

### Rendering Issues

#### Windows Rendering Unresponsiveness

**Issue**: When using PettingZoo's MPE environment on Windows systems, the rendering window may become unresponsive.

**Solution**:
1. Replace the official `simple_env.py` file with our fixed version:
```bash
# Copy the fixed renderer to your PettingZoo installation path
cp envs/simple_env_fixed_render.py <YOUR_PETTINGZOO_PATH>/pettingzoo/mpe/_mpe_utils/simple_env.py
```

But, I suggest you find the `simple_env.py` file in your PettingZoo installation path and replace it with the fixed version `simple_env_fixed_render.py`. **Copy and paste the code into the file manually.**

2. The key fix is adding proper event handling to ensure it works on all platforms:
```python
# Add event handling to fix rendering issues on Windows
for event in pygame.event.get():
    if event.type == pygame.QUIT:
        pygame.quit()
        return
    if event.type == pygame.WINDOWCLOSE:
        pygame.quit()
        return
pygame.event.pump()  # Ensure the event system runs properly
```
### PettingZoo Version Compatibility
**Issue**: This project requires PettingZoo 1.24.4, but the official PyPI repository only offers version 1.24.3.

**Solution**:
Install version 1.24.4 from GitHub source:
```bash
pip install "pettingzoo[mpe] @ git+https://github.com/Farama-Foundation/PettingZoo.git"
```

Or use the provided installation script:
```python
python utils/setupPettingzoo.py
```

### Other Common Issues
#### Visdom Server Connection Issues

**Issue**: Unable to connect to the Visdom server.

**Solution**:

1. Ensure the Visdom server is running: python -m visdom.server
2. Check if the port is in use, try specifying another port: python -m visdom.server -port 8098
3. Make sure the firewall is not blocking the Visdom service


#### Reward Function Modification
**Issue**: The default reward configuration cannot train good policies, especially for the adversary agents.

**Solution**:
Modify the reward function in the `simple_tag.py` file (located in the PettingZoo MPE library):
1. Set the `shape` parameter to `True` (default is `False`)
2. Add boundary penalties for adversaries
3. Adjust collision reward values

Key modifications example:
```python
    def reward(self, agent, world): # å•ä¸ªagentd çš„ reward
        # Agents are rewarded based on minimum agent distance to each landmark
        main_reward = (
            self.adversary_reward(agent, world)
            if agent.adversary
            else self.agent_reward(agent, world)
        )
        # print(f"main_reward{main_reward}")
        return main_reward

    def agent_reward(self, agent, world):
        # Agents are negatively rewarded if caught by adversaries
        rew = 0
        shape = True  # Ronchy æ”¹ä¸ºTrue
        adversaries = self.adversaries(world)
        if (
            shape
        ):  # reward can optionally be shaped (increased reward for increased distance from adversary)
            # for adv in adversaries:
            #     rew += 0.1 * np.sqrt(
            #         np.sum(np.square(agent.state.p_pos - adv.state.p_pos))
            #     )
            pass  #Ronchy ä¿®æ”¹
        # agent.collide default value is True
        if agent.collide:
            for a in adversaries:
                if self.is_collision(a, agent):
                    rew -= 0  # default value = 10

        # agents are penalized for exiting the screen, so that they can be caught by the adversaries
        def bound(x):
            if x < 0.9:
                return 0
            if x < 1.0:
                return (x - 0.9) * 10
            return min(np.exp(2 * x - 2), 10)

        for p in range(world.dim_p):
            x = abs(agent.state.p_pos[p])
            rew -= bound(x)

        return rew

    def adversary_reward(self, agent, world):
        # Adversaries are rewarded for collisions with agents
        rew = 0
        shape = True  #Ronchy æ”¹ä¸ºTrueï¼Œdefault: False
        agents = self.good_agents(world)
        adversaries = self.adversaries(world)
        if (
            shape
        ):  # reward can optionally be shaped (decreased reward for increased distance from agents)
            for adv in adversaries:
                # print("rew_a"   # a åªæœ‰ä¸€ä¸ªï¼Œæ‰€ä»¥minæ— æ‰€è°“
                #     ,[np.sqrt(np.sum(np.square(a.state.p_pos - adv.state.p_pos)))
                #     for a in agents])
                rew -= 0.1 * min(  # a åªæœ‰ä¸€ä¸ªï¼Œæ‰€ä»¥minæ— æ‰€è°“
                    np.sqrt(np.sum(np.square(a.state.p_pos - adv.state.p_pos)))
                    for a in agents
                )
        if agent.collide:  # ä¸é€ƒè·‘è€…ç›¸ç¢°
            for ag in agents:
                for adv in adversaries: 
                    if self.is_collision(ag, adv):
                        rew += 10
        # TODO: è¿½æ•è€…ä¹Ÿè¦åŠ è¾¹ç•Œæƒ©ç½šï¼
        def bound(x):
            if x < 0.9:
                return 0
            if x < 1.0:
                return (x - 0.9) * 10
            return min(np.exp(2 * x - 2), 10)

        for p in range(world.dim_p):
            x = abs(agent.state.p_pos[p])
            rew -= bound(x)
        
        return rew

```



# Known Issues & Solutions | å·²çŸ¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ
[ğŸ‡ºğŸ‡¸ English](#english) | ğŸ‡¨ğŸ‡³ [ä¸­æ–‡](#chinese)

<a id="chinese"></a>
## ä¸­æ–‡

æœ¬æ–‡æ¡£åˆ—å‡ºäº†é¡¹ç›®ä¸­å·²çŸ¥çš„é—®é¢˜åŠå…¶è§£å†³æ–¹æ¡ˆã€‚

### ç›®å½•
- [æ¸²æŸ“é—®é¢˜](#æ¸²æŸ“é—®é¢˜)
- [PettingZooç‰ˆæœ¬å…¼å®¹æ€§](#pettingzooç‰ˆæœ¬å…¼å®¹æ€§)
- [å…¶ä»–å¸¸è§é—®é¢˜](#å…¶ä»–å¸¸è§é—®é¢˜)

### æ¸²æŸ“é—®é¢˜

#### Windowsç³»ç»Ÿæ¸²æŸ“æ— å“åº”

**é—®é¢˜æè¿°**ï¼šåœ¨Windowsç³»ç»Ÿä¸Šï¼Œä½¿ç”¨PettingZooçš„MPEç¯å¢ƒæ—¶ï¼Œæ¸²æŸ“çª—å£å¯èƒ½ä¼šå˜å¾—æ— å“åº”ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨æˆ‘ä»¬ä¿®å¤åçš„`simple_env.py`æ–‡ä»¶æ›¿æ¢å®˜æ–¹ç‰ˆæœ¬ï¼š
```bash
# å°†ä¿®å¤åçš„æ¸²æŸ“å™¨å¤åˆ¶åˆ°æ‚¨çš„PettingZooå®‰è£…è·¯å¾„ä¸­
cp envs/simple_env_fixed_render.py <YOUR_PETTINGZOO_PATH>/pettingzoo/mpe/_mpe_utils/simple_env.py
```

2. ä¿®å¤çš„å…³é”®åœ¨äºæ·»åŠ äº†é€‚å½“çš„äº‹ä»¶å¤„ç†ï¼Œç¡®ä¿åœ¨æ‰€æœ‰å¹³å°ä¸Šéƒ½èƒ½æ­£å¸¸å·¥ä½œï¼š
```python
# æ·»åŠ äº‹ä»¶å¤„ç†, è§£å†³windowsæ¸²æŸ“æŠ¥é”™
for event in pygame.event.get():
    if event.type == pygame.QUIT:
        pygame.quit()
        return
    if event.type == pygame.WINDOWCLOSE:
        pygame.quit()
        return
pygame.event.pump()  # ç¡®ä¿äº‹ä»¶ç³»ç»Ÿæ­£å¸¸è¿è¡Œ
```

### PettingZooç‰ˆæœ¬å…¼å®¹æ€§
#### é—®é¢˜æè¿° 

æœ¬é¡¹ç›®éœ€è¦PettingZoo 1.24.4ç‰ˆæœ¬ï¼Œä½†å®˜æ–¹PyPIä»“åº“æœ€æ–°ç‰ˆæœ¬ä»…ä¸º1.24.3
#### è§£å†³æ–¹æ¡ˆ
ä»GitHubæºç å®‰è£…1.24.4ç‰ˆæœ¬ï¼š
```bash
pip install "pettingzoo[mpe] @ git+https://github.com/Farama-Foundation/PettingZoo.git"
```
æˆ–ä½¿ç”¨æä¾›çš„å®‰è£…è„šæœ¬ï¼š
```bash
python utils/setupPettingzoo.py
```

### å…¶ä»–å¸¸è§é—®é¢˜

#### VisdomæœåŠ¡å™¨è¿æ¥é—®é¢˜

**é—®é¢˜æè¿°**ï¼šæ— æ³•è¿æ¥åˆ°VisdomæœåŠ¡å™¨ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®ä¿VisdomæœåŠ¡å™¨å·²å¯åŠ¨ï¼š`python -m visdom.server`
2. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼Œå¯ä»¥å°è¯•æŒ‡å®šå…¶ä»–ç«¯å£ï¼š`python -m visdom.server -port 8098`
3. ç¡®ä¿é˜²ç«å¢™æœªé˜»æ­¢VisdomæœåŠ¡


#### å¥–åŠ±å‡½æ•°ä¿®æ”¹
**é—®é¢˜æè¿°**ï¼šå®˜æ–¹çš„å¥–åŠ±é…ç½®æ— æ³•è®­ç»ƒå‡ºå¥½çš„æ•ˆæœï¼Œç‰¹åˆ«æ˜¯è¿½æ•è€…çš„å¥–åŠ±å‡½æ•°éœ€è¦ä¿®æ”¹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä¿®æ”¹`simple_tag.py`æ–‡ä»¶ä¸­çš„å¥–åŠ±å‡½æ•°ï¼ˆä½äºPettingZooçš„MPEåº“æ–‡ä»¶ä¸­ï¼‰ï¼š
1. å°†`shape`å‚æ•°è®¾ç½®ä¸º`True`ï¼ˆé»˜è®¤ä¸º`False`ï¼‰
2. ä¸ºè¿½æ•è€…æ·»åŠ è¾¹ç•Œæƒ©ç½š
3. è°ƒæ•´ç¢°æ’å¥–åŠ±å€¼

å…³é”®ä¿®æ”¹ç¤ºä¾‹ï¼š
```python
    def reward(self, agent, world): # å•ä¸ªagentd çš„ reward
        # Agents are rewarded based on minimum agent distance to each landmark
        main_reward = (
            self.adversary_reward(agent, world)
            if agent.adversary
            else self.agent_reward(agent, world)
        )
        # print(f"main_reward{main_reward}")
        return main_reward

    def agent_reward(self, agent, world):
        # Agents are negatively rewarded if caught by adversaries
        rew = 0
        shape = True  # Ronchy æ”¹ä¸ºTrue
        adversaries = self.adversaries(world)
        if (
            shape
        ):  # reward can optionally be shaped (increased reward for increased distance from adversary)
            # for adv in adversaries:
            #     rew += 0.1 * np.sqrt(
            #         np.sum(np.square(agent.state.p_pos - adv.state.p_pos))
            #     )
            pass  #Ronchy ä¿®æ”¹
        # agent.collide default value is True
        if agent.collide:
            for a in adversaries:
                if self.is_collision(a, agent):
                    rew -= 0  # default value = 10

        # agents are penalized for exiting the screen, so that they can be caught by the adversaries
        def bound(x):
            if x < 0.9:
                return 0
            if x < 1.0:
                return (x - 0.9) * 10
            return min(np.exp(2 * x - 2), 10)

        for p in range(world.dim_p):
            x = abs(agent.state.p_pos[p])
            rew -= bound(x)

        return rew

    def adversary_reward(self, agent, world):
        # Adversaries are rewarded for collisions with agents
        rew = 0
        shape = True  #Ronchy æ”¹ä¸ºTrueï¼Œdefault: False
        agents = self.good_agents(world)
        adversaries = self.adversaries(world)
        if (
            shape
        ):  # reward can optionally be shaped (decreased reward for increased distance from agents)
            for adv in adversaries:
                # print("rew_a"   # a åªæœ‰ä¸€ä¸ªï¼Œæ‰€ä»¥minæ— æ‰€è°“
                #     ,[np.sqrt(np.sum(np.square(a.state.p_pos - adv.state.p_pos)))
                #     for a in agents])
                rew -= 0.1 * min(  # a åªæœ‰ä¸€ä¸ªï¼Œæ‰€ä»¥minæ— æ‰€è°“
                    np.sqrt(np.sum(np.square(a.state.p_pos - adv.state.p_pos)))
                    for a in agents
                )
        if agent.collide:  # ä¸é€ƒè·‘è€…ç›¸ç¢°
            for ag in agents:
                for adv in adversaries: 
                    if self.is_collision(ag, adv):
                        rew += 10
        # TODO: è¿½æ•è€…ä¹Ÿè¦åŠ è¾¹ç•Œæƒ©ç½šï¼
        def bound(x):
            if x < 0.9:
                return 0
            if x < 1.0:
                return (x - 0.9) * 10
            return min(np.exp(2 * x - 2), 10)

        for p in range(world.dim_p):
            x = abs(agent.state.p_pos[p])
            rew -= bound(x)
        
        return rew
```

